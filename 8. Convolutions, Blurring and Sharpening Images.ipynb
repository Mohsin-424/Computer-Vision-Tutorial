{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbzEr_26Xdsv"
   },
   "source": [
    "![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n",
    "\n",
    "# **Convolutions, Blurring and Sharpening Images**\n",
    "\n",
    "####**In this lesson we'll learn:**\n",
    "\n",
    "1. Convolution Operations\n",
    "2. Blurring\n",
    "3. Denoising\n",
    "4. Sharpening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2294,
     "status": "ok",
     "timestamp": 1636922351780,
     "user": {
      "displayName": "Rajeev Ratan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64",
      "userId": "08597265227091462140"
     },
     "user_tz": 0
    },
    "id": "W2S13M3FXTw0",
    "outputId": "d3e076e5-259a-4fac-d7e5-a7ef0a0aef00"
   },
   "outputs": [],
   "source": [
    "# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define our imshow function \n",
    "def imshow(title = \"Image\", image = None, size = 10):\n",
    "    w, h = image.shape[0], image.shape[1]\n",
    "    aspect_ratio = w/h\n",
    "    plt.figure(figsize=(size * aspect_ratio,size))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Download and unzip our images\n",
    "# !wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n",
    "# !unzip -qq images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk9_QtV2ZhYC"
   },
   "source": [
    "### **Blurring using Convolutions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2555,
     "status": "ok",
     "timestamp": 1636922567511,
     "user": {
      "displayName": "Rajeev Ratan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64",
      "userId": "08597265227091462140"
     },
     "user_tz": 0
    },
    "id": "OqXRpsU5XbHM",
    "outputId": "4c97d903-4fed-458e-e07f-91fc4ad9a644"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/flowers.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginal Image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Creating our 3 x 3 kernel\u001b[39;00m\n\u001b[0;32m      8\u001b[0m kernel_3x3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m9\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(title, image, size)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     w, h \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m     aspect_ratio \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m/\u001b[39mh\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(size \u001b[38;5;241m*\u001b[39m aspect_ratio,size))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/flowers.jpeg')\n",
    "imshow('Original Image', image)\n",
    "\n",
    "# Creating our 3 x 3 kernel\n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "# We use the cv2.fitler2D to conovlve the kernal with an image \n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "imshow('3x3 Kernel Blurring', blurred)\n",
    "\n",
    "# Creating our 7 x 7 kernel\n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "imshow('7x7 Kernel Blurring', blurred2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Other commonly used blurring methods in OpenCV**\n",
    "\n",
    "- Regular Blurring\n",
    "- Gaussian Blurring\n",
    "- Median Blurring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2430,
     "status": "ok",
     "timestamp": 1636922631538,
     "user": {
      "displayName": "Rajeev Ratan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64",
      "userId": "08597265227091462140"
     },
     "user_tz": 0
    },
    "id": "OLsF4yeTaay9",
    "outputId": "81e8477d-2f86-4f61-b6fe-e175dcb54ce0"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\box_filter.dispatch.cpp:446: error: (-215:Assertion failed) !_src.empty() in function 'cv::boxFilter'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/flowers.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Averaging done by convolving the image with a normalized box filter. \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# This takes the pixels under the box and replaces the central element\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Box size needs to odd and positive \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m blur \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m imshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAveraging\u001b[39m\u001b[38;5;124m'\u001b[39m, blur)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Instead of box filter, gaussian kernel\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\box_filter.dispatch.cpp:446: error: (-215:Assertion failed) !_src.empty() in function 'cv::boxFilter'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/flowers.jpeg')\n",
    "\n",
    "# Averaging done by convolving the image with a normalized box filter. \n",
    "# This takes the pixels under the box and replaces the central element\n",
    "# Box size needs to odd and positive \n",
    "blur = cv2.blur(image, (5,5))\n",
    "imshow('Averaging', blur)\n",
    "\n",
    "# Instead of box filter, gaussian kernel\n",
    "Gaussian = cv2.GaussianBlur(image, (5,5), 0)\n",
    "imshow('Gaussian Blurring', Gaussian)\n",
    "\n",
    "# Takes median of all the pixels under kernel area and central \n",
    "# element is replaced with this median value\n",
    "median = cv2.medianBlur(image, 5)\n",
    "imshow('Median Blurring', median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Other commonly used blurring methods in OpenCV**\n",
    "\n",
    "- Regular Blurring\n",
    "- Gaussian Blurring\n",
    "- Median Blurring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Other commonly used blurring methods in OpenCV**\n",
    "\n",
    "- Regular Blurring\n",
    "- Gaussian Blurring\n",
    "- Median Blurring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Other commonly used blurring methods in OpenCV**\n",
    "\n",
    "- Regular Blurring\n",
    "- Gaussian Blurring\n",
    "- Median Blurring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Other commonly used blurring methods in OpenCV**\n",
    "\n",
    "- Regular Blurring\n",
    "- Gaussian Blurring\n",
    "- Median Blurring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhGkCuCtbBdK"
   },
   "source": [
    "### **Bilateral Filter**\n",
    "\n",
    "#### `dst = cv.bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]])`\n",
    "\n",
    "- **src** Source 8-bit or floating-point, 1-channel or 3-channel image.\n",
    "- **dst** Destination image of the same size and type as src .\n",
    "- **d** Diameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from sigmaSpace.\n",
    "- **sigmaColor** Filter sigma in the color space. A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color.\n",
    "- **sigmaSpace** Filter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When d>0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is proportional to sigmaSpace.\n",
    "- **borderType** border mode used to extrapolate pixels outside of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1636922686830,
     "user": {
      "displayName": "Rajeev Ratan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64",
      "userId": "08597265227091462140"
     },
     "user_tz": 0
    },
    "id": "v0ggNFqDbDQs",
    "outputId": "bd6e87f4-51ae-4e5c-9e23-797351e3abb1"
   },
   "outputs": [],
   "source": [
    "# Bilateral is very effective in noise removal while keeping edges sharp\n",
    "bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "imshow('Bilateral Blurring', bilateral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQw0iF1FdZMA"
   },
   "source": [
    "## **Image De-noising - Non-Local Means Denoising**\n",
    "\n",
    "**There are 4 variations of Non-Local Means Denoising:**\n",
    "\n",
    "- cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "- cv2.fastNlMeansDenoisingColored() - works with a color image.\n",
    "- cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images)\n",
    "- cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images.\n",
    "\n",
    "`fastNlMeansDenoisingColored(InputArray src, OutputArray dst, float h=3, float hColor=3, int templateWindowSize=7, int searchWindowSize=21 )¶`\n",
    "\n",
    "#### Parameters for fastNlMeansDenoisingColored:\n",
    "\n",
    "- **src** – Input 8-bit 3-channel image.\n",
    "- **dst** – Output image with the same size and type as src .\n",
    "  templateWindowSize – Size in pixels of the template patch that is used to compute weights. Should be odd. Recommended value 7 pixels\n",
    "- **searchWindowSize** – Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time. Recommended value 21 pixels\n",
    "- **h** – Parameter regulating filter strength for luminance component. Bigger h value perfectly removes noise but also removes image details, smaller h value preserves details but also preserves some noise\n",
    "- **hColor** – The same as h but for color components. For most images value equals 10 will be enought to remove colored noise and do not distort colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1636922729350,
     "user": {
      "displayName": "Rajeev Ratan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64",
      "userId": "08597265227091462140"
     },
     "user_tz": 0
    },
    "id": "GRXmyd3Uchkn",
    "outputId": "46aca120-4ed2-4e99-fa8c-8a3816aaeed0"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('images/hilton.jpeg')\n",
    "imshow('Original', image)\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21)\n",
    "imshow('fastNlMeansDenoisingColored', dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqNwMkAef6X2"
   },
   "source": [
    "### **Sharpening Images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1963,
     "status": "ok",
     "timestamp": 1636922782825,
     "user": {
      "displayName": "Rajeev Ratan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64",
      "userId": "08597265227091462140"
     },
     "user_tz": 0
    },
    "id": "ablnOpgjctFu",
    "outputId": "9907e42c-b2ca-43d4-cd4c-b93508f7924c"
   },
   "outputs": [],
   "source": [
    "# Loading our image\n",
    "image = cv2.imread('images/hilton.jpeg')\n",
    "imshow('Original', image)\n",
    "\n",
    "# Create our shapening kernel, remember it must sum to one \n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 9,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "# applying the sharpening kernel to the image\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "imshow('Sharpened Image', sharpened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KX4PQ9IM2ng"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMaLRdoCBrbUU51PLjPRH+B",
   "collapsed_sections": [],
   "name": "8. Convolutions, Blurring and Sharpening Images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
